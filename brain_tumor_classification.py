# -*- coding: utf-8 -*-
"""Brain_Tumor_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EhID1is9xMq_rl9-3mu78zUrm3KMPbHM

**Import Lib**
"""

import numpy as np
import pandas as pd
import os
import cv2
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt
import seaborn as sns

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Now download the dataset from Kaggle (change this to the correct dataset)
!kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri

# Unzip the dataset
!unzip brain-tumor-classification-mri.zip

"""**Data Preparation**"""

# Setting up paths and parameters
image_size = 150
labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']
X_train = []
Y_train = []

# Load training data
for label in labels:
    folderPath = os.path.join('Training', label)
    for image_name in os.listdir(folderPath):
        image_path = os.path.join(folderPath, image_name)
        img = cv2.imread(image_path)
        img = cv2.resize(img, (image_size, image_size))
        X_train.append(img)
        Y_train.append(label)

# Load testing data (same as above)
for label in labels:
    folderPath = os.path.join('Testing', label)
    for image_name in os.listdir(folderPath):
        image_path = os.path.join(folderPath, image_name)
        img = cv2.imread(image_path)
        img = cv2.resize(img, (image_size, image_size))
        X_train.append(img)
        Y_train.append(label)

# Convert data to NumPy arrays
X_train = np.array(X_train)
Y_train = np.array(Y_train)

# Shuffle data
X_train, Y_train = shuffle(X_train, Y_train, random_state=101)

# Split into train/test sets
X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=101)

# Convert labels to categorical format
y_train_new = [labels.index(i) for i in y_train]
y_train = to_categorical(y_train_new)

y_test_new = [labels.index(i) for i in y_test]
y_test = to_categorical(y_test_new)

print(f"Training data shape: {X_train.shape}")
print(f"Testing data shape: {X_test.shape}")



"""**Model Building**"""

model = Sequential()

# Add convolutional layers
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Dropout(0.3))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))

# Add fully connected layers
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(4, activation='softmax'))

# Model summary
model.summary()

"""**Training**"""

from keras.optimizers import Adam

# Set a learning rate
learning_rate = 0.0001  # You can adjust this value

# Create Adam optimizer with specified learning rate
optimizer = Adam(learning_rate=learning_rate)

# Compile the model with the specified optimizer and learning rate
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=20, validation_split=0.1)

"""**Visualize Results**"""

# Plot accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))
plt.figure(figsize=(14, 7))
plt.plot(epochs, acc, 'r', label='Training Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.legend()
plt.show()

# Plot loss
loss = history.history['loss']
val_loss = history.history['val_loss']
plt.figure(figsize=(14, 7))
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.legend()
plt.show()

"""**Testing and Predictions**"""

from tensorflow.keras.preprocessing import image

# Load a sample image from the dataset and make a prediction
img = cv2.imread('Training/pituitary_tumor/p (107).jpg')
img = cv2.resize(img, (150, 150))
img_array = img.reshape(1, 150, 150, 3)

# Predict the class
prediction = model.predict(img_array)
predicted_class = labels[np.argmax(prediction)]
print(f"Predicted Class: {predicted_class}")

# Show the image
plt.imshow(img)
plt.title(predicted_class)
plt.show()

# Load a sample image from the dataset and make a prediction
img = cv2.imread('/content/Testing/glioma_tumor/image(79).jpg')
img = cv2.resize(img, (150, 150))
img_array = img.reshape(1, 150, 150, 3)

# Predict the class
prediction = model.predict(img_array)
predicted_class = labels[np.argmax(prediction)]
print(f"Predicted Class: {predicted_class}")

# Show the image
plt.imshow(img)
plt.title(predicted_class)
plt.show()



# Save the model as an H5 file
model.save("braintumor_model.h5")

# Save the model in the TensorFlow SavedModel format (.keras)
model.save("braintumor_model.keras", save_format="keras")

import json

# Convert the history to a dictionary
history_dict = history.history

# Save the training history as a JSON file
with open("training_history.json", "w") as json_file:
    json.dump(history_dict, json_file)

from google.colab import files

# Download the H5 model file
files.download('braintumor_model.h5')

# Download the Keras model file
files.download('braintumor_model.keras')

# Download the training history (assuming you've already saved it)
files.download('training_history.json')

